{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4ac4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import ast\n",
    "import warnings\n",
    "from torch.utils.data import DataLoader\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "from src.modeling.siglabv2.siglabv2 import SigLabV2\n",
    "from src.modeling.datasets.siglab_dataset import SigLabDataset\n",
    "from src.run import lead_sets\n",
    "from src.utils import count_parameters, confusion_matrix, apply_preprocessors\n",
    "from src.data.load_ptbdata_new import PRECORDIAL_LEADS, ALL_LEADS\n",
    "from src.evaluation import lead_level_accuracy, set_level_accuracy\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "686e3931",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from wandb: 63_siglabv2_inception_gru_2_2\n",
      "+----------------------------------------+------------+\n",
      "|                Modules                 | Parameters |\n",
      "+----------------------------------------+------------+\n",
      "|             encoder.alpha              |     1      |\n",
      "| encoder.cnn_encoder.0.branch1.0.weight |     32     |\n",
      "|  encoder.cnn_encoder.0.branch1.0.bias  |     32     |\n",
      "| encoder.cnn_encoder.0.branch1.1.weight |     32     |\n",
      "|  encoder.cnn_encoder.0.branch1.1.bias  |     32     |\n",
      "| encoder.cnn_encoder.0.branch2.0.weight |     1      |\n",
      "|  encoder.cnn_encoder.0.branch2.0.bias  |     1      |\n",
      "| encoder.cnn_encoder.0.branch2.1.weight |     1      |\n",
      "|  encoder.cnn_encoder.0.branch2.1.bias  |     1      |\n",
      "| encoder.cnn_encoder.0.branch2.3.weight |    160     |\n",
      "|  encoder.cnn_encoder.0.branch2.3.bias  |     32     |\n",
      "| encoder.cnn_encoder.0.branch2.4.weight |     32     |\n",
      "|  encoder.cnn_encoder.0.branch2.4.bias  |     32     |\n",
      "| encoder.cnn_encoder.0.branch3.0.weight |     1      |\n",
      "|  encoder.cnn_encoder.0.branch3.0.bias  |     1      |\n",
      "| encoder.cnn_encoder.0.branch3.1.weight |     1      |\n",
      "|  encoder.cnn_encoder.0.branch3.1.bias  |     1      |\n",
      "| encoder.cnn_encoder.0.branch3.3.weight |    352     |\n",
      "|  encoder.cnn_encoder.0.branch3.3.bias  |     32     |\n",
      "| encoder.cnn_encoder.0.branch3.4.weight |     32     |\n",
      "|  encoder.cnn_encoder.0.branch3.4.bias  |     32     |\n",
      "| encoder.cnn_encoder.0.branch4.1.weight |     32     |\n",
      "|  encoder.cnn_encoder.0.branch4.1.bias  |     32     |\n",
      "| encoder.cnn_encoder.0.branch4.2.weight |     32     |\n",
      "|  encoder.cnn_encoder.0.branch4.2.bias  |     32     |\n",
      "| encoder.cnn_encoder.2.branch1.0.weight |    4096    |\n",
      "|  encoder.cnn_encoder.2.branch1.0.bias  |     32     |\n",
      "| encoder.cnn_encoder.2.branch1.1.weight |     32     |\n",
      "|  encoder.cnn_encoder.2.branch1.1.bias  |     32     |\n",
      "| encoder.cnn_encoder.2.branch2.0.weight |    8192    |\n",
      "|  encoder.cnn_encoder.2.branch2.0.bias  |     64     |\n",
      "| encoder.cnn_encoder.2.branch2.1.weight |     64     |\n",
      "|  encoder.cnn_encoder.2.branch2.1.bias  |     64     |\n",
      "| encoder.cnn_encoder.2.branch2.3.weight |   10240    |\n",
      "|  encoder.cnn_encoder.2.branch2.3.bias  |     32     |\n",
      "| encoder.cnn_encoder.2.branch2.4.weight |     32     |\n",
      "|  encoder.cnn_encoder.2.branch2.4.bias  |     32     |\n",
      "| encoder.cnn_encoder.2.branch3.0.weight |    8192    |\n",
      "|  encoder.cnn_encoder.2.branch3.0.bias  |     64     |\n",
      "| encoder.cnn_encoder.2.branch3.1.weight |     64     |\n",
      "|  encoder.cnn_encoder.2.branch3.1.bias  |     64     |\n",
      "| encoder.cnn_encoder.2.branch3.3.weight |   22528    |\n",
      "|  encoder.cnn_encoder.2.branch3.3.bias  |     32     |\n",
      "| encoder.cnn_encoder.2.branch3.4.weight |     32     |\n",
      "|  encoder.cnn_encoder.2.branch3.4.bias  |     32     |\n",
      "| encoder.cnn_encoder.2.branch4.1.weight |    4096    |\n",
      "|  encoder.cnn_encoder.2.branch4.1.bias  |     32     |\n",
      "| encoder.cnn_encoder.2.branch4.2.weight |     32     |\n",
      "|  encoder.cnn_encoder.2.branch4.2.bias  |     32     |\n",
      "|    encoder.cnn_post_layers.2.weight    |   16384    |\n",
      "|     encoder.cnn_post_layers.2.bias     |    128     |\n",
      "|        encoder.gru.weight_ih_l0        |   49152    |\n",
      "|        encoder.gru.weight_hh_l0        |   49152    |\n",
      "|         encoder.gru.bias_ih_l0         |    384     |\n",
      "|         encoder.gru.bias_hh_l0         |    384     |\n",
      "|        encoder.gru.weight_ih_l1        |   49152    |\n",
      "|        encoder.gru.weight_hh_l1        |   49152    |\n",
      "|         encoder.gru.bias_ih_l1         |    384     |\n",
      "|         encoder.gru.bias_hh_l1         |    384     |\n",
      "|        encoder.attn_proj.weight        |   16384    |\n",
      "|        encoder.attn_vec.weight         |    128     |\n",
      "|          encoder.fc.0.weight           |   16384    |\n",
      "|           encoder.fc.0.bias            |    128     |\n",
      "|       encoder.merge_norm.weight        |    128     |\n",
      "|        encoder.merge_norm.bias         |    128     |\n",
      "|            init_head.weight            |    768     |\n",
      "|             init_head.bias             |     6      |\n",
      "| attention_blocks.0.mha.in_proj_weight  |   49152    |\n",
      "|  attention_blocks.0.mha.in_proj_bias   |    384     |\n",
      "| attention_blocks.0.mha.out_proj.weight |   16384    |\n",
      "|  attention_blocks.0.mha.out_proj.bias  |    128     |\n",
      "|    attention_blocks.0.ffn.0.weight     |   65536    |\n",
      "|     attention_blocks.0.ffn.0.bias      |    512     |\n",
      "|    attention_blocks.0.ffn.2.weight     |   65536    |\n",
      "|     attention_blocks.0.ffn.2.bias      |    128     |\n",
      "|  attention_blocks.0.layernorm1.weight  |    128     |\n",
      "|   attention_blocks.0.layernorm1.bias   |    128     |\n",
      "|  attention_blocks.0.layernorm2.weight  |    128     |\n",
      "|   attention_blocks.0.layernorm2.bias   |    128     |\n",
      "| attention_blocks.1.mha.in_proj_weight  |   49152    |\n",
      "|  attention_blocks.1.mha.in_proj_bias   |    384     |\n",
      "| attention_blocks.1.mha.out_proj.weight |   16384    |\n",
      "|  attention_blocks.1.mha.out_proj.bias  |    128     |\n",
      "|    attention_blocks.1.ffn.0.weight     |   65536    |\n",
      "|     attention_blocks.1.ffn.0.bias      |    512     |\n",
      "|    attention_blocks.1.ffn.2.weight     |   65536    |\n",
      "|     attention_blocks.1.ffn.2.bias      |    128     |\n",
      "|  attention_blocks.1.layernorm1.weight  |    128     |\n",
      "|   attention_blocks.1.layernorm1.bias   |    128     |\n",
      "|  attention_blocks.1.layernorm2.weight  |    128     |\n",
      "|   attention_blocks.1.layernorm2.bias   |    128     |\n",
      "| attention_blocks.2.mha.in_proj_weight  |   49152    |\n",
      "|  attention_blocks.2.mha.in_proj_bias   |    384     |\n",
      "| attention_blocks.2.mha.out_proj.weight |   16384    |\n",
      "|  attention_blocks.2.mha.out_proj.bias  |    128     |\n",
      "|    attention_blocks.2.ffn.0.weight     |   65536    |\n",
      "|     attention_blocks.2.ffn.0.bias      |    512     |\n",
      "|    attention_blocks.2.ffn.2.weight     |   65536    |\n",
      "|     attention_blocks.2.ffn.2.bias      |    128     |\n",
      "|  attention_blocks.2.layernorm1.weight  |    128     |\n",
      "|   attention_blocks.2.layernorm1.bias   |    128     |\n",
      "|  attention_blocks.2.layernorm2.weight  |    128     |\n",
      "|   attention_blocks.2.layernorm2.bias   |    128     |\n",
      "| attention_blocks.3.mha.in_proj_weight  |   49152    |\n",
      "|  attention_blocks.3.mha.in_proj_bias   |    384     |\n",
      "| attention_blocks.3.mha.out_proj.weight |   16384    |\n",
      "|  attention_blocks.3.mha.out_proj.bias  |    128     |\n",
      "|    attention_blocks.3.ffn.0.weight     |   65536    |\n",
      "|     attention_blocks.3.ffn.0.bias      |    512     |\n",
      "|    attention_blocks.3.ffn.2.weight     |   65536    |\n",
      "|     attention_blocks.3.ffn.2.bias      |    128     |\n",
      "|  attention_blocks.3.layernorm1.weight  |    128     |\n",
      "|   attention_blocks.3.layernorm1.bias   |    128     |\n",
      "|  attention_blocks.3.layernorm2.weight  |    128     |\n",
      "|   attention_blocks.3.layernorm2.bias   |    128     |\n",
      "| attention_blocks.4.mha.in_proj_weight  |   49152    |\n",
      "|  attention_blocks.4.mha.in_proj_bias   |    384     |\n",
      "| attention_blocks.4.mha.out_proj.weight |   16384    |\n",
      "|  attention_blocks.4.mha.out_proj.bias  |    128     |\n",
      "|    attention_blocks.4.ffn.0.weight     |   65536    |\n",
      "|     attention_blocks.4.ffn.0.bias      |    512     |\n",
      "|    attention_blocks.4.ffn.2.weight     |   65536    |\n",
      "|     attention_blocks.4.ffn.2.bias      |    128     |\n",
      "|  attention_blocks.4.layernorm1.weight  |    128     |\n",
      "|   attention_blocks.4.layernorm1.bias   |    128     |\n",
      "|  attention_blocks.4.layernorm2.weight  |    128     |\n",
      "|   attention_blocks.4.layernorm2.bias   |    128     |\n",
      "|     classifier.classifier.0.weight     |   32768    |\n",
      "|      classifier.classifier.0.bias      |    256     |\n",
      "|     classifier.classifier.2.weight     |   32768    |\n",
      "|      classifier.classifier.2.bias      |    128     |\n",
      "|     classifier.classifier.4.weight     |    768     |\n",
      "|      classifier.classifier.4.bias      |     6      |\n",
      "+----------------------------------------+------------+\n",
      "Total Trainable Params: 1365845\n",
      "Encoder Trainable Params: 307017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1365845, 307017)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_path = \"nateml-maastricht-university/bachelors-thesis\"\n",
    "#run_id = \"kuq34vvz\"\n",
    "#version = \"v24\"\n",
    "run_id = \"yh0by5uj\"  # replace with wandb run id of interest\n",
    "version = \"v30\"  # model checkpoint\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the torch model from wandb\n",
    "api = wandb.Api()\n",
    "\n",
    "run = api.run(f\"{project_path}/{run_id}\")\n",
    "config = dict(run.config)\n",
    "\n",
    "# Get the run name\n",
    "run_name = run.name\n",
    "\n",
    "artifact = api.artifact(f\"{project_path}/{run_name}:{version}\")\n",
    "artifact_path = artifact.download()\n",
    "\n",
    "# Convert config to omegaconf\n",
    "cfg = OmegaConf.create(config)\n",
    "\n",
    "# Load the model\n",
    "checkpoint = torch.load(artifact_path + f\"/{run_name}.pth\", map_location=device)\n",
    "\n",
    "# Cast the model to the correct type\n",
    "model = SigLabV2(cfg.model).to(device)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()  # Put into evaluation mode\n",
    "\n",
    "# Count number of parameters\n",
    "print(f\"Loaded model from wandb: {run_name}\")\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "303095fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2183, 6, 1000])\n",
      "(2198, 6)\n"
     ]
    }
   ],
   "source": [
    "dataset_path = Path(\"../../\" + cfg.dataset.path)\n",
    "if OmegaConf.select(cfg, \"dataset.only_precordial\"):\n",
    "    dataset_path = dataset_path / \"precordial\"\n",
    "else:\n",
    "    dataset_path = dataset_path / \"all\"\n",
    "dataset_path = dataset_path.resolve()\n",
    "\n",
    "val_data = np.load(dataset_path / \"val.npy\")\n",
    "test_data = np.load(dataset_path / \"test.npy\")\n",
    "\n",
    "# Apply preprocessors\n",
    "val_data = apply_preprocessors(val_data,\n",
    "                               cfg.dataset.sampling_rate,\n",
    "                               cfg.preprocessor_group.preprocessors)\n",
    "test_data = apply_preprocessors(test_data,\n",
    "                                 cfg.dataset.sampling_rate,\n",
    "                                 cfg.preprocessor_group.preprocessors)\n",
    " \n",
    "# Convert to torch tensor\n",
    "val_data = torch.from_numpy(val_data).float().to(device)\n",
    "val_data = val_data.permute(0, 2, 1)\n",
    "print(val_data.shape)\n",
    "\n",
    "test_data = torch.from_numpy(test_data).float().to(device)\n",
    "test_data = test_data.permute(0, 2, 1)\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "lead_filter = lead_sets[OmegaConf.select(cfg, \"run.leads\", default=\"precordial\")]\n",
    "dataset = SigLabDataset(test_data, filter_leads=lead_filter)\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False)\n",
    "\n",
    "# I need to reorder val_data to match the order of the labels in the dataset\n",
    "if OmegaConf.select(cfg, \"dataset.only_precordial\") or OmegaConf.select(cfg, \"dataset.only_precordial\") is None:\n",
    "    val_data = val_data[:, [PRECORDIAL_LEADS.index(lead) for lead in lead_filter], :]\n",
    "    test_data = test_data[:, [PRECORDIAL_LEADS.index(lead) for lead in lead_filter], :]\n",
    "else:\n",
    "    val_data = val_data[:, [ALL_LEADS.index(lead) for lead in lead_filter], :]\n",
    "    test_data = test_data[:, [ALL_LEADS.index(lead) for lead in lead_filter], :]\n",
    "\n",
    "# Load metadata\n",
    "meta_val = pd.read_csv(dataset_path / \"meta_val.csv\")\n",
    "meta_test = pd.read_csv(dataset_path / \"meta_test.csv\")\n",
    "meta = meta_test.copy()\n",
    "meta['scp_codes'] = meta['scp_codes'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "THRESHOLD = 0.5\n",
    "def codes_above_threshold(code_dict, thr=THRESHOLD):\n",
    "    return {code for code, prob in code_dict.items() if prob >= thr}\n",
    "\n",
    "meta[\"present_codes\"] = meta[\"scp_codes\"].apply(lambda x: codes_above_threshold(x, THRESHOLD))\n",
    "\n",
    "# Treat diagnostic superclass as lists\n",
    "meta[\"diagnostic_superclass\"] = meta[\"diagnostic_superclass\"].apply(lambda x: ast.literal_eval(x))\n",
    "# Now convert to a set\n",
    "meta[\"diagnostic_superclass\"] = meta[\"diagnostic_superclass\"].apply(lambda x: set(x))\n",
    "\n",
    "c = cfg.model.num_classes\n",
    "logits = np.zeros((len(dataset), c, c))\n",
    "init_logits = np.zeros((len(dataset), c, c))\n",
    "targets = np.zeros((len(dataset), c))\n",
    "\n",
    "for idx, (signals, lead_labels) in enumerate(dataloader):\n",
    "    signals = signals.to(device)\n",
    "    lead_labels = lead_labels.to(device)\n",
    "\n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        these_logits = model(signals)\n",
    "        logits[(idx * batch_size):(idx * batch_size + batch_size)] = these_logits.cpu().numpy()\n",
    "        targets[(idx * batch_size):(idx * batch_size + batch_size)] = lead_labels.cpu().numpy()\n",
    "\n",
    "predictions = logits.argmax(axis=-1)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e96e1f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confusion matrices for each PTB-XL diagnostic class\n",
    "# Get indices where 'NORM' is in the 'diagnostic_superclass' column which contains lists\n",
    "norm_idx = np.where(meta['diagnostic_superclass'].apply(lambda x: 'NORM' in x))[0]\n",
    "cm_norm = confusion_matrix(predictions[norm_idx], targets[norm_idx])\n",
    "\n",
    "mi_idx = np.where(meta['diagnostic_superclass'].apply(lambda x: 'MI' in x))[0]\n",
    "cm_mi = confusion_matrix(predictions[mi_idx], targets[mi_idx])\n",
    "\n",
    "cd_idx = np.where(meta['diagnostic_superclass'].apply(lambda x: 'CD' in x))[0]\n",
    "cm_cd = confusion_matrix(predictions[cd_idx], targets[cd_idx])\n",
    "\n",
    "mi_cd_idx = np.where(meta['diagnostic_superclass'].apply(lambda x: 'MI' in x or 'CD' in x))[0]\n",
    "cm_mi_cd = confusion_matrix(predictions[mi_cd_idx], targets[mi_cd_idx])\n",
    "\n",
    "sttc_idx = np.where(meta['diagnostic_superclass'].apply(lambda x: 'STTC' in x))[0]\n",
    "cm_sttc = confusion_matrix(predictions[sttc_idx], targets[sttc_idx])\n",
    "\n",
    "hyp_idx = np.where(meta['diagnostic_superclass'].apply(lambda x: 'HYP' in x))[0]\n",
    "cm_hyp = confusion_matrix(predictions[hyp_idx], targets[hyp_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36f564cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead-level accuracy: 0.9810\n",
      "Set-level accuracy: 0.9472\n",
      "Normal class accuracy: 0.9922\n",
      "MI class accuracy: 0.9718\n",
      "MI+CD class accuracy: 0.9723\n"
     ]
    }
   ],
   "source": [
    "lead_acc = lead_level_accuracy(predictions=predictions, targets=targets)\n",
    "set_acc = set_level_accuracy(predictions=predictions, targets=targets)\n",
    "print(f\"Lead-level accuracy: {lead_acc:.4f}\")\n",
    "print(f\"Set-level accuracy: {set_acc:.4f}\")\n",
    "\n",
    "norm_acc = cm_norm.diagonal().sum() / cm_norm.sum()\n",
    "print(f\"Normal class accuracy: {norm_acc:.4f}\")\n",
    "\n",
    "mi_acc = cm_mi.diagonal().sum() / cm_mi.sum()\n",
    "print(f\"MI class accuracy: {mi_acc:.4f}\")\n",
    "\n",
    "mi_cd_acc = cm_mi_cd.diagonal().sum() / cm_mi_cd.sum()\n",
    "print(f\"MI+CD class accuracy: {mi_cd_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8bc9d50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilson score interval for lead-level accuracy: [0.9785, 0.9832], z-score: 1.9594\n",
      "Wilson score interval for set-level accuracy: [0.9370, 0.9558], z-score: 1.9650\n",
      "Wilson score interval for normal class: [0.9896, 0.9942], z-score: 1.9630\n",
      "Wilson score interval for MI class: [0.9656, 0.9769], z-score: 1.9595\n",
      "Wilson score interval for MI+CD class: [0.9674, 0.9764], z-score: 1.9620\n"
     ]
    }
   ],
   "source": [
    "# Wilson score interval for lead-level accuracy\n",
    "def wilson_score_interval(successes, trials, confidence=0.95):\n",
    "    # Convert confidence level to z-score\n",
    "    z = abs(np.percentile(np.random.normal(size=1000000), (1 - confidence) * 100 / 2))\n",
    "    p = successes / trials\n",
    "    denominator = 1 + z**2 / trials\n",
    "    centre_adjusted_probability = p + z**2 / (2 * trials)\n",
    "    adjusted_standard_deviation = np.sqrt((p * (1 - p) + z**2 / (4 * trials)) / trials)\n",
    "    lower_bound = (centre_adjusted_probability - z * adjusted_standard_deviation) / denominator\n",
    "    upper_bound = (centre_adjusted_probability + z * adjusted_standard_deviation) / denominator\n",
    "    return lower_bound, upper_bound, z\n",
    "\n",
    "lead_successes = np.sum(predictions.flatten() == targets.flatten(), axis=0)\n",
    "lead_trials = len(predictions.flatten())\n",
    "\n",
    "lower_bound, upper_bound, z = wilson_score_interval(lead_successes, lead_trials)\n",
    "print(f\"Wilson score interval for lead-level accuracy: [{lower_bound:.4f}, {upper_bound:.4f}], z-score: {z:.4f}\")\n",
    "\n",
    "\n",
    "set_successes = np.sum(np.all(predictions == targets, axis=1))\n",
    "set_trials = len(predictions)\n",
    "\n",
    "set_lower_bound, set_upper_bound, z = wilson_score_interval(set_successes, set_trials)\n",
    "print(f\"Wilson score interval for set-level accuracy: [{set_lower_bound:.4f}, {set_upper_bound:.4f}], z-score: {z:.4f}\")\n",
    "\n",
    "normal_successes = np.sum(predictions[norm_idx].flatten() == targets[norm_idx].flatten())\n",
    "normal_trials = len(predictions[norm_idx].flatten())\n",
    "\n",
    "normal_lower_bound, normal_upper_bound, z = wilson_score_interval(normal_successes, normal_trials)\n",
    "print(f\"Wilson score interval for normal class: [{normal_lower_bound:.4f}, {normal_upper_bound:.4f}], z-score: {z:.4f}\")\n",
    "\n",
    "mi_successes = np.sum(predictions[mi_idx].flatten() == targets[mi_idx].flatten())\n",
    "mi_trials = len(predictions[mi_idx].flatten())\n",
    "\n",
    "mi_lower_bound, mi_upper_bound, z = wilson_score_interval(mi_successes, mi_trials)\n",
    "print(f\"Wilson score interval for MI class: [{mi_lower_bound:.4f}, {mi_upper_bound:.4f}], z-score: {z:.4f}\")\n",
    "\n",
    "mi_cd_successes = np.sum(predictions[mi_cd_idx].flatten() == targets[mi_cd_idx].flatten())\n",
    "mi_cd_trials = len(predictions[mi_cd_idx].flatten())\n",
    "mi_cd_lower_bound, mi_cd_upper_bound, z = wilson_score_interval(mi_cd_successes, mi_cd_trials)\n",
    "print(f\"Wilson score interval for MI+CD class: [{mi_cd_lower_bound:.4f}, {mi_cd_upper_bound:.4f}], z-score: {z:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
